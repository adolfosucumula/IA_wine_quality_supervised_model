{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #toolbox to work with dataframes\n",
    "import numpy as np #toolbox to work with narrays\n",
    "import matplotlib.pyplot as plt #toolbox to do plots\n",
    "from sklearn.svm import SVC #load the support vector machine model functions\n",
    "from sklearn.model_selection import train_test_split #load the function to split train and test sets\n",
    "from sklearn import metrics # get the report\n",
    "from sklearn.metrics import classification_report # get the report\n",
    "from sklearn import preprocessing # normalize the features\n",
    "from sklearn.preprocessing import MinMaxScaler # normalize the features\n",
    "from sklearn.feature_selection import SelectKBest #load the feature selector model  \n",
    "from sklearn.feature_selection import chi2 #feature selector algorithm\n",
    "\n",
    "\n",
    "def normalized_data (df,t):\n",
    "\n",
    "    if (t==1):\n",
    "        d=df.copy() # min max normalization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            max =df.iloc[:,each_collum].max()\n",
    "            min =df.iloc[:,each_collum].min()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-min)/(max-min)\n",
    "    elif (t==2):\n",
    "        d=df.copy() # mean normalization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            max =df.iloc[:,each_collum].max()\n",
    "            min =df.iloc[:,each_collum].min()\n",
    "            mean =df.iloc[:,each_collum].mean()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-mean)/(max-min)\n",
    "    \n",
    "    else:\n",
    "        d=df.copy() # standardization\n",
    "        for each_collum in range(0,df.shape[1]):\n",
    "            mean =df.iloc[:,each_collum].mean()\n",
    "            std =df.iloc[:,each_collum].std()\n",
    "            d.iloc[:,each_collum]=(d.iloc[:,each_collum]-mean)/(std)\n",
    "\n",
    "    return d\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prodrigues\\AppData\\Local\\Temp\\ipykernel_17632\\31263044.py:2: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  df = pd.read_csv('winequality-white.csv',';') #open the database\n"
     ]
    }
   ],
   "source": [
    "# 1st step database opening\n",
    "df = pd.read_csv('winequality-white.csv',';') #open the database\n",
    "\n",
    "# split the database in target and features\n",
    "target=df.iloc[:,-1]\n",
    "df=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step - features normalization\n",
    "d_n=normalized_data (df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd step - load and design the classifiers\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,ExtraTreesClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "classifiers = [\n",
    "    SVC(gamma='auto'),\n",
    "    GaussianProcessClassifier(1.0* RBF(1.0)),\n",
    "    LinearSVC(),\n",
    "    SGDClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(solver='lbfgs'),\n",
    "    LogisticRegressionCV(cv=3),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(n_estimators=300),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=300, max_features=1),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    MLPClassifier(alpha=1,max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    OneVsRestClassifier(LinearSVC(random_state=0)),\n",
    "    GradientBoostingClassifier(),\n",
    "    SGDClassifier(),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "346        0.173077          0.254902     0.060241        0.010736   0.065282   \n",
      "1862       0.336538          0.049020     0.186747        0.026074   0.133531   \n",
      "3529       0.317308          0.264706     0.162651        0.038344   0.074184   \n",
      "397        0.240385          0.117647     0.240964        0.013804   0.083086   \n",
      "1986       0.365385          0.078431     0.246988        0.019939   0.112760   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "3161       0.221154          0.088235     0.253012        0.222393   0.071217   \n",
      "1141       0.528846          0.254902     0.295181        0.102761   0.127596   \n",
      "3075       0.250000          0.068627     0.240964        0.013804   0.097923   \n",
      "4032       0.288462          0.186275     0.132530        0.263804   0.074184   \n",
      "2095       0.442308          0.196078     0.240964        0.127301   0.115727   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "346              0.062718              0.136891  0.067284  0.581818   \n",
      "1862             0.069686              0.220418  0.101986  0.472727   \n",
      "3529             0.090592              0.290023  0.049933  0.490909   \n",
      "397              0.114983              0.227378  0.088490  0.672727   \n",
      "1986             0.087108              0.329466  0.127048  0.436364   \n",
      "...                   ...                   ...       ...       ...   \n",
      "3161             0.090592              0.266821  0.187584  0.136364   \n",
      "1141             0.097561              0.317865  0.209948  0.409091   \n",
      "3075             0.073171              0.180974  0.050318  0.354545   \n",
      "4032             0.048780              0.248260  0.227299  0.318182   \n",
      "2095             0.108014              0.317865  0.225371  0.618182   \n",
      "\n",
      "      sulphates   alcohol  \n",
      "346    0.337209  0.516129  \n",
      "1862   0.813953  0.564516  \n",
      "3529   0.186047  0.822581  \n",
      "397    0.325581  0.548387  \n",
      "1986   0.360465  0.338710  \n",
      "...         ...       ...  \n",
      "3161   0.290698  0.241935  \n",
      "1141   0.453488  0.354839  \n",
      "3075   0.279070  0.677419  \n",
      "4032   0.360465  0.193548  \n",
      "2095   0.279070  0.209677  \n",
      "\n",
      "[3673 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# split data for training and testing your model\n",
    "X_train, X_test, y_train, y_test = train_test_split(d_n, target, train_size = 0.75) # 75% of data goes for training and 25% goes for testing\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the function to performe feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#load the feature selection algorithms\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFpr\n",
    "from sklearn.feature_selection import SelectFdr\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "\n",
    "# function to do feature selection\n",
    "def feature_selector(X_train,y_train,X_test,type,i):\n",
    "    if (type == 1):\n",
    "#ANOVA F-value between label/feature for classification tasks.\n",
    "        bestfeatures = SelectKBest(score_func = f_classif, k=i)\n",
    "    elif(type == 2):\n",
    "#Mutual information for a discrete target.\n",
    "        bestfeatures = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "    elif(type == 3):\n",
    "    #Chi-squared stats of non-negative features for classification tasks.\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=i)\n",
    "    elif(type == 4):\n",
    "#Select features based on an estimated false discovery rate.\n",
    "        bestfeatures = SelectKBest(score_func=SelectFdr, k=i)\n",
    "    elif(type == 5):\n",
    "#Select features based on family-wise error rate.\n",
    "        bestfeatures = SelectKBest(score_func=SelectFwe, k=i)\n",
    "#Perform the feature based on selected algorithm\n",
    "    fit = bestfeatures.fit(X_train,y_train)\n",
    "    cols_idxs = fit.get_support(indices=True)\n",
    "    Xt=X_train.iloc[:,cols_idxs] # extract the best features for training\n",
    "    Xteste=X_test.iloc[:,cols_idxs] # extract the best features for testing\n",
    "    return Xt,Xteste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for doing the classification\n",
    "# the Function receives as inputs:\n",
    "# models -> machine learning models\n",
    "# Xt -> training dataframe\n",
    "# Xteste -> testing dataframe\n",
    "# yTrain -> training label\n",
    "def classification(models,Xt,yTrain,Xteste):\n",
    "    models.fit(Xt, yTrain) # function to train the model\n",
    "#y_pred means label predictions of the models\n",
    "    y_pred=models.predict(Xteste) # function for testing the model\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries for checking the classification report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "# Function defined for checking the classification performance of the model\n",
    "# inputs:\n",
    "# y_test -> the true label\n",
    "# ypred -> model's label\n",
    "# outputs: classification report metrics\n",
    "# accuracy, precision, recall, f1-score\n",
    "def classification_reports(y_test,ypred):\n",
    "    report=classification_report(y_test, ypred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    precision = report['macro avg']['precision']\n",
    "    recall = report['macro avg']['recall']\n",
    "    f1 = report['macro avg']['f1-score']\n",
    "    return [accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  accuracy  precision    recall        f1\n",
      "0      3.0  0.442449   0.205934  0.143611  0.089013\n",
      "1      4.0  0.440816   0.062974  0.142857  0.087414\n",
      "2      5.0  0.466939   0.160464  0.208048  0.180528\n",
      "3      6.0  0.490612   0.142913  0.179673  0.156236\n",
      "4      7.0  0.515918   0.215575  0.203059  0.194211\n",
      "5      8.0  0.458776   0.333157  0.240705  0.241544\n",
      "6      9.0  0.502857   0.329954  0.238127  0.249615\n",
      "7     10.0  0.505306   0.255426  0.216152  0.217049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\prodrigues\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#iterative process to find the e.g. the best 3 features, 4, 5, 6,...,\n",
    "# until total of features\n",
    "# classification and models performance checking.\n",
    "\n",
    "perf_results=pd.DataFrame()\n",
    "\n",
    "for i in range(3,d_n.shape[1]):\n",
    "    Xt,Xteste = feature_selector(X_train,y_train,X_test,2,i)\n",
    "    ypred = classification(classifiers[3],Xt,y_train,Xteste)\n",
    "    accuracy, precision, recall, f1 = classification_reports(y_test,ypred)\n",
    "    perf_results[i-3]=[i,accuracy, precision, recall, f1]\n",
    "\n",
    "perf_results=perf_results.T # how to transpose a dataframe collumns <-> rows.\n",
    "perf_results.columns=['feature','accuracy','precision','recall','f1']\n",
    "#print the classification of classifier 4 by using the best 3, 4, ..., total of features\n",
    "print(perf_results)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f681d13594f6d13fd384c1eed34ffbd142ac2c86c0f865443692fcf61f9efdbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
